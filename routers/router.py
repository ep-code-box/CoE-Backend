"""
ë¼ìš°í„° ë…¸ë“œ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
"""

import json
from typing import List, Dict, Any
from core.schemas import ChatState
from core.llm_client import client, default_model
from tools.utils import find_last_user_message


def router_node(state: ChatState, tool_descriptions: List[Dict[str, Any]]) -> dict:
    """
    ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ë¼ìš°í„° ë…¸ë“œì…ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì±„íŒ… ìƒíƒœ
        tool_descriptions: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì˜ ì„¤ëª… ëª©ë¡
        
    Returns:
        dict: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ ì •ë³´
    """
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ original_inputì— ì €ì¥
    last_user_message = find_last_user_message(state["messages"])
    
    # ìœ íš¨í•œ ë„êµ¬ ì´ë¦„ ëª©ë¡ ìƒì„±
    VALID_TOOL_NAMES = [tool['name'] for tool in tool_descriptions]
    
    # ë™ì ìœ¼ë¡œ ë„êµ¬ ì„¤ëª… ëª©ë¡ ìƒì„±
    tool_descriptions_string = "\n".join(
        [f"- '{tool['name']}': {tool['description']}" for tool in tool_descriptions]
    )
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = f"""ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ë‹¤ìŒ ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.
{tool_descriptions_string}

íŠ¹ë³„ ê·œì¹™:
- ë§Œì•½ ë°”ë¡œ ì´ì „ì˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ìŠ¹ì¸ì„ ìš”ì²­í•˜ëŠ” ë‚´ìš©ì´ê³  ì‚¬ìš©ìê°€ 'approve' ë˜ëŠ” 'reject'ì™€ ìœ ì‚¬í•œ ì‘ë‹µì„ í–ˆë‹¤ë©´, ë°˜ë“œì‹œ 'process_approval' ë„êµ¬ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {{"next_tool": "ì„ íƒí•œ ë„êµ¬"}}"""

    prompt_messages = state["messages"] + [
        {"role": "system", "content": system_prompt}
    ]
    
    try:
        resp = client.chat.completions.create(
            model=default_model.model_id,  # ê¸°ë³¸ ëª¨ë¸ ID ì‚¬ìš©
            messages=prompt_messages,
            response_format={"type": "json_object"}  # JSON ëª¨ë“œ í™œì„±í™”
        )
        # OpenAI ê°ì²´ë¥¼ dictë¡œ ë³€í™˜í•˜ì—¬ íƒ€ì… ì¼ê´€ì„± ìœ ì§€
        response_message = resp.choices[0].message.model_dump()

        try:
            # LLM ì‘ë‹µ(JSON) íŒŒì‹±
            choice_json = json.loads(response_message["content"])
            choice = choice_json.get("next_tool")
            print(f"ğŸ¤–[Router]: LLMì´ ì„ íƒí•œ ë„êµ¬: {choice}")
            
            if choice not in VALID_TOOL_NAMES:  # ìœ íš¨í•œ ë„êµ¬ ì´ë¦„ ëª©ë¡ìœ¼ë¡œ ê²€ì‚¬
                raise ValueError(f"LLMì´ ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬({choice})ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
            
            # ë‹¤ìŒ ë…¸ë“œë¥¼ ìƒíƒœì— ì €ì¥í•˜ê³ , LLMì˜ ì‘ë‹µë„ ê¸°ë¡ì— ì¶”ê°€
            return {
                "messages": [response_message], 
                "next_node": choice, 
                "original_input": last_user_message
            }
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  ê·¸ë˜í”„ ì¢…ë£Œ
            error_msg = f"ë¼ìš°í„°ê°€ LLM ì‘ë‹µì„ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
            print(f"ğŸ¤–[Router]: Error - {error_msg}")
            return {
                "messages": [response_message, {"role": "system", "content": error_msg}], 
                "next_node": "error"
            }

    except Exception as e:
        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  ê·¸ë˜í”„ ì¢…ë£Œ
        error_msg = f"ë¼ìš°í„° API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
        print(f"ğŸ¤–[Router]: Error - {error_msg}")
        return {
            "messages": [{"role": "system", "content": error_msg}], 
            "next_node": "error"
        }