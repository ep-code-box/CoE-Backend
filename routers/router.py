"""
ë¼ìš°í„° ë…¸ë“œ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
"""

import json
import logging
from typing import List, Dict, Any, Optional
from core.schemas import ChatState
from core.llm_client import client, default_model
from tools.core.utils import extract_git_url, find_last_user_message

logger = logging.getLogger(__name__)


def router_node(state: ChatState, tool_descriptions: List[Dict[str, Any]], model_id: Optional[str] = None) -> dict:
    
    """
    ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ë¼ìš°í„° ë…¸ë“œì…ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì±„íŒ… ìƒíƒœ
        tool_descriptions: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì˜ ì„¤ëª… ëª©ë¡
        model_id: ë¼ìš°íŒ…ì— ì‚¬ìš©í•  LLM ëª¨ë¸ ID (ì„ íƒ ì‚¬í•­). ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©.
        
    Returns:
        dict: ì—…ë°ì´íŠ¸ëœ ìƒíƒœ ì •ë³´
    """
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ original_inputì— ì €ì¥
    last_user_message = find_last_user_message(state["messages"])
    
    # ìœ íš¨í•œ ë„êµ¬ ì´ë¦„ ëª©ë¡ ìƒì„±
    VALID_TOOL_NAMES = [tool['name'] for tool in tool_descriptions]
    
    # --- ê°•ì œ ë„êµ¬ ì„ íƒ ë¡œì§ (Pre-processing) ---
    # Git Repository URLê³¼ ê°œë°œ ê°€ì´ë“œ ê´€ë ¨ í‚¤ì›Œë“œ ì¡°í•© ì‹œ guide_extraction ê°•ì œ ì„ íƒ
    git_url = extract_git_url(last_user_message)
    dev_guide_keywords = ["ê°œë°œê°€ì´ë“œ", "í‘œì¤€ê°œë°œê°€ì´ë“œ", "ê³µí†µì½”ë“œí™”", "ê³µí†µí•¨ìˆ˜", "ê°€ì´ë“œ"]
    
    if git_url and any(keyword in last_user_message for keyword in dev_guide_keywords):
        print(f"ğŸ¤–[Router]: Forcing selection of 'guide_extraction' due to Git URL and dev guide keywords.")
        return {
            "messages": [], 
            "next_node": "guide_extraction", 
            "original_input": last_user_message
        }
    # --- ê°•ì œ ë„êµ¬ ì„ íƒ ë¡œì§ ë ---

    # ë™ì ìœ¼ë¡œ ë„êµ¬ ì„¤ëª… ëª©ë¡ ìƒì„±
    tool_descriptions_string = "\n".join(
        [f"- '{tool['name']}': {tool['description']}" for tool in tool_descriptions]
    )
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” AI ë¼ìš°í„°ì…ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ê³¼ ê° ë„êµ¬ì˜ ì„¤ëª…ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.

--- ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ---
{tool_descriptions_string}

--- íŠ¹ë³„ ê·œì¹™ ---
1. **ì‚¬ìš©ìì˜ ìš”ì²­ì— Git Repository URL (ì˜ˆ: https://github.com/...)ì´ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆê³ , 'ê°œë°œ ê°€ì´ë“œ', 'í‘œì¤€ ê°œë°œ ê°€ì´ë“œ', 'ê³µí†µ ì½”ë“œí™”', 'ê³µí†µ í•¨ìˆ˜' ë“±ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, ë‹¤ë¥¸ ì–´ë–¤ ë„êµ¬ë³´ë‹¤ ìš°ì„ í•˜ì—¬ ë°˜ë“œì‹œ 'guide_extraction' ë„êµ¬ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.**
2. ë§Œì•½ ë°”ë¡œ ì´ì „ì˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ìŠ¹ì¸ì„ ìš”ì²­í•˜ëŠ” ë‚´ìš©ì´ê³  ì‚¬ìš©ìê°€ 'approve' ë˜ëŠ” 'reject'ì™€ ìœ ì‚¬í•œ ì‘ë‹µì„ í–ˆë‹¤ë©´, ë°˜ë“œì‹œ 'process_approval' ë„êµ¬ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
3. ê·¸ ì™¸ ì‚¬ìš©ìì˜ ìš”ì²­ì— URLì´ í¬í•¨ë˜ì–´ ìˆê³ , í•´ë‹¹ URLì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ê±°ë‚˜ íŠ¹ì • ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ëª©ì ì´ë¼ë©´, URLì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
4. ì‚¬ìš©ìì˜ ì…ë ¥ì—ì„œ URLì„ ì£¼ì˜ ê¹Šê²Œ ì°¾ì•„ë‚´ê³ , í•´ë‹¹ URLì´ ì–´ë–¤ ë„êµ¬ì™€ ê´€ë ¨ë  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {{'next_tool': 'ì„ íƒí•œ ë„êµ¬'}} """  

    prompt_messages = state["messages"] + [
        {"role": "system", "content": system_prompt}
    ]
    
    try:
        # ì‚¬ìš©í•  ëª¨ë¸ ID ê²°ì •
        llm_model_id = model_id if model_id else default_model.model_id
        
        resp = client.chat.completions.create(
            model=llm_model_id,  # ë™ì ìœ¼ë¡œ ê²°ì •ëœ ëª¨ë¸ ID ì‚¬ìš©
            messages=prompt_messages,
            response_format={"type": "json_object"}  # JSON ëª¨ë“œ í™œì„±í™”
        )
        # OpenAI ê°ì²´ë¥¼ dictë¡œ ë³€í™˜í•˜ì—¬ íƒ€ì… ì¼ê´€ì„± ìœ ì§€
        response_message = resp.choices[0].message.model_dump()


        try:
            # LLM ì‘ë‹µ(JSON) íŒŒì‹±
            choice_json = json.loads(response_message["content"])
            choice = choice_json.get("next_tool")
            
            # ë„êµ¬ ì„ íƒ ë¡œê·¸ ì¶”ê°€ (ì „ìš© ë¡œê±° ì‚¬ìš©)
            tool_logger = logging.getLogger("tool_tracker")
            tool_logger.info(f"TOOL_SELECTED: '{choice}' | USER_INPUT: '{last_user_message[:100]}{'...' if len(last_user_message) > 100 else ''}'")
            logger.info(f"ğŸ”§ [TOOL_SELECTION] Router selected tool: '{choice}' for user input: '{last_user_message[:100]}{'...' if len(last_user_message) > 100 else ''}'")
            print(f"ğŸ¤–[Router]: LLMì´ ì„ íƒí•œ ë„êµ¬: {choice}")
            
            # ëŒ€í™” ì´ë ¥ì— ë„êµ¬ ì„ íƒ ì •ë³´ ì €ì¥
            tool_context = state.get("_tool_context", {})
            session_id = tool_context.get("session_id")
            chat_service = tool_context.get("chat_service")
            turn_number = tool_context.get("turn_number", 1)
            
            if chat_service and session_id:
                try:
                    chat_service.save_chat_message(
                        session_id=session_id,
                        role="system",
                        content=f"[ë„êµ¬ ì„ íƒ] '{choice}' ë„êµ¬ê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì…ë ¥: {last_user_message[:100]}{'...' if len(last_user_message) > 100 else ''}",
                        turn_number=turn_number,
                        selected_tool=choice,
                        tool_metadata={
                            "selection_reason": "LLM ë¼ìš°í„°ì— ì˜í•œ ìë™ ì„ íƒ",
                            "user_input_preview": last_user_message[:100] if last_user_message else None
                        }
                    )
                except Exception as db_error:
                    logger.warning(f"ë„êµ¬ ì„ íƒ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {db_error}")
            
            if choice not in VALID_TOOL_NAMES:  # ìœ íš¨í•œ ë„êµ¬ ì´ë¦„ ëª©ë¡ìœ¼ë¡œ ê²€ì‚¬
                logger.error(f"ğŸš¨ [TOOL_SELECTION_ERROR] Invalid tool selected: '{choice}'. Valid tools: {VALID_TOOL_NAMES}")
                raise ValueError(f"LLMì´ ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬({choice})ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
            
            # ë‹¤ìŒ ë…¸ë“œë¥¼ ìƒíƒœì— ì €ì¥í•˜ê³ , LLMì˜ ì‘ë‹µë„ ê¸°ë¡ì— ì¶”ê°€
            return {
                "messages": [response_message], 
                "next_node": choice, 
                "original_input": last_user_message
            }
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  ê·¸ë˜í”„ ì¢…ë£Œ
            error_msg = f"ë¼ìš°í„°ê°€ LLM ì‘ë‹µì„ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
            logger.error(f"ğŸš¨ [TOOL_SELECTION_ERROR] Router parsing failed: {error_msg}")
            print(f"ğŸ¤–[Router]: Error - {error_msg}")
            return {
                "messages": [response_message, {"role": "system", "content": error_msg}], 
                "next_node": "error"
            }

    except Exception as e:
        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  ê·¸ë˜í”„ ì¢…ë£Œ
        error_msg = f"ë¼ìš°í„° API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
        logger.error(f"ğŸš¨ [TOOL_SELECTION_ERROR] Router API call failed: {error_msg}")
        print(f"ğŸ¤–[Router]: Error - {error_msg}")
        return {
            "messages": [{"role": "system", "content": error_msg}], 
            "next_node": "error"
        }
