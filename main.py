import json
import os
import uuid
from typing import Dict
from fastapi import FastAPI, HTTPException, Depends
from fastapi.responses import JSONResponse
from langgraph.graph import StateGraph, START, END
from dotenv import load_dotenv
from sqlalchemy.orm import Session

# ë¶„ë¦¬ëœ ëª¨ë“ˆì—ì„œ ìŠ¤í‚¤ë§ˆì™€ ë„êµ¬ ë…¸ë“œ ê°€ì ¸ì˜¤ê¸°
from schemas import (
    ChatState, ChatRequest, ChatResponse, Message,
    LangFlowJSON, SaveFlowRequest, FlowListResponse, ExecuteFlowRequest
)
from llm_client import client, default_model # LLM í´ë¼ì´ì–¸íŠ¸ì™€ ê¸°ë³¸ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
from tools.utils import find_last_user_message
from tools.registry import load_all_tools
from models import model_registry # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê°€ì ¸ì˜¤ê¸°

# ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì„í¬íŠ¸
from database import get_db, init_database
from db_service import LangFlowService, DatabaseService

# 1) ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ í†µí•´ ëª¨ë“  ë…¸ë“œ, ì„¤ëª…, ì—£ì§€ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œ
all_nodes, all_tool_descriptions, all_special_edges = load_all_tools()

# 'end' ë„êµ¬ì— ëŒ€í•œ ì„¤ëª… ì¶”ê°€
all_tool_descriptions.append({
    "name": "end",
    "description": "ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ëë‚´ê³  ì‹¶ì–´í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
})

# 2) ë¼ìš°í„°ê°€ ì‚¬ìš©í•  ìœ íš¨í•œ ë„êµ¬ ì´ë¦„ ëª©ë¡ ìƒì„±
VALID_TOOL_NAMES = [tool['name'] for tool in all_tool_descriptions]

# 3) ë¼ìš°í„° ë…¸ë“œ: ë™ì ìœ¼ë¡œ ìƒì„±ëœ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
def router_node(state: ChatState) -> dict:
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ original_inputì— ì €ì¥
    last_user_message = find_last_user_message(state["messages"]) # utilsì—ì„œ ê°€ì ¸ì˜¨ í•¨ìˆ˜ ì‚¬ìš©
    
    # ë™ì ìœ¼ë¡œ ë„êµ¬ ì„¤ëª… ëª©ë¡ ìƒì„±
    tool_descriptions_string = "\n".join(
        [f"- '{tool['name']}': {tool['description']}" for tool in all_tool_descriptions]
    )
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = f"""ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ë‹¤ìŒ ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.
{tool_descriptions_string}

íŠ¹ë³„ ê·œì¹™:
- ë§Œì•½ ë°”ë¡œ ì´ì „ì˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ìŠ¹ì¸ì„ ìš”ì²­í•˜ëŠ” ë‚´ìš©ì´ê³  ì‚¬ìš©ìê°€ 'approve' ë˜ëŠ” 'reject'ì™€ ìœ ì‚¬í•œ ì‘ë‹µì„ í–ˆë‹¤ë©´, ë°˜ë“œì‹œ 'process_approval' ë„êµ¬ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {{"next_tool": "ì„ íƒí•œ ë„êµ¬"}}"""

    prompt_messages = state["messages"] + [
        {"role": "system", "content": system_prompt}
    ]
    try:
        resp = client.chat.completions.create(
            model=default_model.model_id, # ê¸°ë³¸ ëª¨ë¸ ID ì‚¬ìš©
            messages=prompt_messages,
            response_format={"type": "json_object"} # JSON ëª¨ë“œ í™œì„±í™”
        )
        # OpenAI ê°ì²´ë¥¼ dictë¡œ ë³€í™˜í•˜ì—¬ íƒ€ì… ì¼ê´€ì„± ìœ ì§€
        response_message = resp.choices[0].message.model_dump()

        try:
            # LLM ì‘ë‹µ(JSON) íŒŒì‹±
            choice_json = json.loads(response_message["content"])
            choice = choice_json.get("next_tool")
            print(f"ğŸ¤–[Router]: LLMì´ ì„ íƒí•œ ë„êµ¬: {choice}")
            if choice not in VALID_TOOL_NAMES: # ìœ íš¨í•œ ë„êµ¬ ì´ë¦„ ëª©ë¡ìœ¼ë¡œ ê²€ì‚¬
                raise ValueError(f"LLMì´ ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬({choice})ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
            # ë‹¤ìŒ ë…¸ë“œë¥¼ ìƒíƒœì— ì €ì¥í•˜ê³ , LLMì˜ ì‘ë‹µë„ ê¸°ë¡ì— ì¶”ê°€
            return {"messages": [response_message], "next_node": choice, "original_input": last_user_message}
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  ê·¸ë˜í”„ ì¢…ë£Œ
            error_msg = f"ë¼ìš°í„°ê°€ LLM ì‘ë‹µì„ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
            print(f"ğŸ¤–[Router]: Error - {error_msg}")
            return {"messages": [response_message, {"role": "system", "content": error_msg}], "next_node": "error"}

    except Exception as e:
        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  ê·¸ë˜í”„ ì¢…ë£Œ
        error_msg = f"ë¼ìš°í„° API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
        print(f"ğŸ¤–[Router]: Error - {error_msg}")
        return {"messages": [{"role": "system", "content": error_msg}], "next_node": "error"}

# 5) ê·¸ë˜í”„ êµ¬ì„± ë° ì»´íŒŒì¼ (ëª¨ë“  ë…¸ë“œì™€ ì—£ì§€ ì¶”ê°€)
graph = StateGraph(ChatState)

# ë¼ìš°í„° ë…¸ë“œ ì¶”ê°€
graph.add_node("router", router_node)

# ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ë¡œë“œí•œ ëª¨ë“  ë„êµ¬ ë…¸ë“œë¥¼ ë™ì ìœ¼ë¡œ ì¶”ê°€
for name, node_func in all_nodes.items():
    graph.add_node(name, node_func)

# ê·¸ë˜í”„ì˜ ì‹œì‘ì ì„ ë¼ìš°í„°ë¡œ ì„¤ì •
graph.set_entry_point("router")

# ë¼ìš°í„°ì˜ ê²°ì •ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¡œ ë¶„ê¸°í•˜ë„ë¡ ë™ì ìœ¼ë¡œ ì—£ì§€ ë§¤í•‘ ìƒì„±
routable_tool_names = [tool['name'] for tool in all_tool_descriptions if tool['name'] != 'end']
edge_mapping = {name: name for name in routable_tool_names}
edge_mapping["combined_tool"] = "api_call"  # 'combined_tool'ì€ 'api_call'ë¡œ ì‹œì‘í•˜ëŠ” íŠ¹ë³„ ì¼€ì´ìŠ¤
edge_mapping["end"] = END
edge_mapping["error"] = END

graph.add_conditional_edges(
    "router",
    lambda state: state["next_node"],
    edge_mapping
)

# ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ë¡œë“œí•œ íŠ¹ë³„í•œ ì—£ì§€ë“¤ì„ ë™ì ìœ¼ë¡œ ì¶”ê°€
special_edge_sources = set()
for edge_config in all_special_edges:
    source_node = edge_config["source"]
    special_edge_sources.add(source_node)
    if edge_config["type"] == "conditional":
        graph.add_conditional_edges(
            source_node,
            edge_config["condition"],
            edge_config["path_map"]
        )
    elif edge_config["type"] == "standard":
        graph.add_edge(source_node, edge_config["target"])

# íŠ¹ë³„í•œ ì—£ì§€ê°€ ì •ì˜ëœ ë…¸ë“œì™€ ë¼ìš°í„°ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ëª¨ë“  ë…¸ë“œëŠ” ì‘ì—… ì™„ë£Œ í›„ ì¢…ë£Œ(END)ë¡œ ì—°ê²°
nodes_with_special_outgoing_edges = special_edge_sources.union({"router"})
for node_name in all_nodes:
    if node_name not in nodes_with_special_outgoing_edges:
        graph.add_edge(node_name, END)

agent = graph.compile(interrupt_after=["human_approval"])

# 7) FastAPI ì•± ìƒì„± ë° ì—”ë“œí¬ì¸íŠ¸
app = FastAPI()

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    print("ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì¤‘...")
    if init_database():
        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    else:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨")

@app.get("/v1/models")
async def list_models():
    """
    models.jsonì— ì •ì˜ëœ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ì˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    OpenAIì˜ /v1/models ì—”ë“œí¬ì¸íŠ¸ì™€ í˜¸í™˜ë˜ëŠ” í˜•ì‹ì…ë‹ˆë‹¤.
    """
    all_models = model_registry.get_models()
    model_data = [
        {"id": model.model_id, "object": "model", "created": 1686935002, "owned_by": model.provider}
        for model in all_models
    ]
    return JSONResponse(content={
        "object": "list",
        "data": model_data
    })

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(req: ChatRequest):
    # Pydantic ëª¨ë¸ì„ ë‚´ë¶€ ìƒíƒœ(dict)ë¡œ ë³€í™˜
    state = {
        "messages": [msg.model_dump() for msg in req.messages],
    }
    # ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë³€ê²½)
    result = await agent.ainvoke(state)
    return ChatResponse(messages=result["messages"])

# LangFlow ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.post("/flows/save")
async def save_flow(req: SaveFlowRequest, db: Session = Depends(get_db)):
    """LangFlow JSONì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        flow_data = req.flow_data.model_dump()
        flow_data["saved_name"] = req.name
        if req.description:
            flow_data["description"] = req.description
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        db_flow = LangFlowService.create_flow(
            db=db,
            name=req.name,
            flow_data=flow_data,
            description=req.description
        )
        
        return {
            "message": f"Flow '{req.name}' saved successfully",
            "id": db_flow.id,
            "name": db_flow.name,
            "created_at": db_flow.created_at.isoformat()
        }
    
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to save flow: {str(e)}")

@app.get("/flows/list", response_model=FlowListResponse)
async def list_flows(db: Session = Depends(get_db)):
    """ì €ì¥ëœ LangFlow ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        db_flows = LangFlowService.get_all_flows(db)
        
        flows = []
        for db_flow in db_flows:
            flows.append({
                "name": db_flow.name,
                "id": str(db_flow.id),
                "description": db_flow.description or "",
                "created_at": db_flow.created_at.isoformat(),
                "updated_at": db_flow.updated_at.isoformat()
            })
        
        return FlowListResponse(flows=flows)
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to list flows: {str(e)}")

@app.get("/flows/{flow_name}")
async def get_flow(flow_name: str, db: Session = Depends(get_db)):
    """íŠ¹ì • LangFlow JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # ì´ë¦„ìœ¼ë¡œ í”Œë¡œìš° ì¡°íšŒ
        db_flow = LangFlowService.get_flow_by_name(db, flow_name)
        
        if not db_flow:
            raise HTTPException(status_code=404, detail=f"Flow '{flow_name}' not found")
        
        # JSON ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        flow_data = LangFlowService.get_flow_data_as_dict(db_flow)
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        flow_data.update({
            "id": db_flow.id,
            "name": db_flow.name,
            "description": db_flow.description,
            "created_at": db_flow.created_at.isoformat(),
            "updated_at": db_flow.updated_at.isoformat()
        })
        
        return flow_data
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get flow: {str(e)}")

@app.delete("/flows/{flow_name}")
async def delete_flow(flow_name: str, db: Session = Depends(get_db)):
    """ì €ì¥ëœ LangFlowë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    try:
        # í”Œë¡œìš° ì‚­ì œ (ì†Œí”„íŠ¸ ì‚­ì œ)
        success = LangFlowService.delete_flow(db, flow_name)
        
        if not success:
            raise HTTPException(status_code=404, detail=f"Flow '{flow_name}' not found")
        
        return {"message": f"Flow '{flow_name}' deleted successfully"}
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete flow: {str(e)}")

# DB ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/db/tables")
async def get_table_info(db: Session = Depends(get_db)):
    """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        table_info = DatabaseService.get_table_info(db)
        return {"tables": table_info}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get table info: {str(e)}")

@app.post("/db/query")
async def execute_query(query: dict, db: Session = Depends(get_db)):
    """SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ (SELECTë§Œ í—ˆìš©)."""
    try:
        sql_query = query.get("query", "").strip()
        if not sql_query:
            raise HTTPException(status_code=400, detail="Query is required")
        
        result = DatabaseService.execute_query(db, sql_query)
        return result
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to execute query: {str(e)}")

# íŒŒì¼ ê¸°ë°˜ ë°ì´í„°ë¥¼ DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
@app.post("/flows/migrate")
async def migrate_flows_from_files(db: Session = Depends(get_db)):
    """ê¸°ì¡´ íŒŒì¼ ê¸°ë°˜ LangFlow ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤."""
    try:
        flows_dir = "flows"
        migrated_count = 0
        errors = []
        
        if not os.path.exists(flows_dir):
            return {"message": "No flows directory found", "migrated_count": 0}
        
        for filename in os.listdir(flows_dir):
            if filename.endswith('.json'):
                filepath = os.path.join(flows_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        flow_data = json.load(f)
                    
                    # íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                    name = flow_data.get("saved_name", filename[:-5])
                    description = flow_data.get("description", "")
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì‹œë„
                    try:
                        LangFlowService.create_flow(
                            db=db,
                            name=name,
                            flow_data=flow_data,
                            description=description
                        )
                        migrated_count += 1
                        print(f"âœ… Migrated flow: {name}")
                    except ValueError as e:
                        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í”Œë¡œìš°ëŠ” ê±´ë„ˆë›°ê¸°
                        if "already exists" in str(e):
                            print(f"âš ï¸ Flow '{name}' already exists, skipping")
                        else:
                            errors.append(f"Flow '{name}': {str(e)}")
                    
                except Exception as e:
                    errors.append(f"File '{filename}': {str(e)}")
                    continue
        
        return {
            "message": f"Migration completed. {migrated_count} flows migrated.",
            "migrated_count": migrated_count,
            "errors": errors
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to migrate flows: {str(e)}")

if __name__ == "__main__":
    import uvicorn

    # .env íŒŒì¼ ë¡œë“œ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ í•„ìš”)
    load_dotenv()

    # í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•´ ê°œë°œ ëª¨ë“œì™€ í”„ë¡œë•ì…˜ ëª¨ë“œë¥¼ êµ¬ë¶„í•©ë‹ˆë‹¤.
    # APP_ENVê°€ 'development'ì¼ ë•Œë§Œ hot-reloadingì„ í™œì„±í™”í•©ë‹ˆë‹¤.
    is_development = os.getenv("APP_ENV") == "development"

    print(f"ğŸš€ Starting server in {'development (hot-reload enabled)' if is_development else 'production'} mode.")

    uvicorn.run(
        "main:app",
        host="0.0.0.0", port=8000, reload=is_development
    )
