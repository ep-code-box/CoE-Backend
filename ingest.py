import os
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings


def main():
    """
    'data' ë””ë ‰í† ë¦¬ì˜ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ì—¬ ì²­í¬ë¡œ ë¶„í• í•˜ê³ ,
    OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ Chroma ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    print("ğŸš€ ë°ì´í„° ì¸ë±ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (OPENAI_API_KEY)
    load_dotenv()

    # 2. ë°ì´í„° ë¡œë“œ
    # 'data' ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    loader = DirectoryLoader('./data/', glob="**/*.md")
    documents = loader.load()
    if not documents:
        print("âš ï¸ 'data' ë””ë ‰í„°ë¦¬ì—ì„œ ì²˜ë¦¬í•  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. í…ìŠ¤íŠ¸ ë¶„í• 
    # ë¬¸ì„œë¥¼ ê´€ë¦¬í•˜ê¸° ì‰¬ìš´ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    texts = text_splitter.split_documents(documents)
    print(f"ğŸ“„ ì´ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ {len(texts)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")

    # 4. ë²¡í„° DBì— ì €ì¥
    # OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.
    # 'db' ë””ë ‰í„°ë¦¬ì— ë°ì´í„°ê°€ ì˜êµ¬ì ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
    Chroma.from_documents(texts, OpenAIEmbeddings(), persist_directory="./db")
    print("âœ… ë°ì´í„° ì¸ë±ì‹± ë° ë²¡í„° DB ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()